{"cells":[{"cell_type":"markdown","metadata":{"id":"iruud8QA-hma"},"source":["# Logging, Tracking, and Debugging Prompts using Comet\n","\n","In this section, we will demonstrate how to log, track, and debug prompt using the `comet-llm` library. `comet-llm` is an open-sourced repo managed by Comet. Please give the repo star if you have a chance and submit any feedback you have! https://github.com/comet-ml/comet-llm\n","\n","Let's first load all the necessary libraries:\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6923,"status":"ok","timestamp":1698764871649,"user":{"displayName":"Daniel Egbo","userId":"12843431213035929983"},"user_tz":-120},"id":"cLNconIi-rhZ"},"outputs":[],"source":["! pip install openai comet-llm --quiet"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1115,"status":"ok","timestamp":1698764877142,"user":{"displayName":"Daniel Egbo","userId":"12843431213035929983"},"user_tz":-120},"id":"WcRfRjy6-hmc"},"outputs":[],"source":["import openai\n","import os\n","import IPython\n","import json\n","import pandas as pd\n","import numpy as np\n","import comet_llm\n","import urllib\n","\n","from dotenv import load_dotenv\n","from pathlib import Path\n","\n","dotenv_path = Path('../.env')\n","load_dotenv(dotenv_path=dotenv_path) \n","\n","# API configuration\n","openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n","COMET_API_KEY = os.getenv(\"COMET_API_KEY\")\n","COMET_WORKSPACE = os.getenv(\"COMET_WORKSPACE\")"]},{"cell_type":"markdown","metadata":{"id":"o8yyTvrK-hmd"},"source":["The function below helps to generate the final results from the model after calling the OpenAI API:"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":381,"status":"ok","timestamp":1698764911272,"user":{"displayName":"Daniel Egbo","userId":"12843431213035929983"},"user_tz":-120},"id":"EiKIWPuQ-hmd"},"outputs":[],"source":["def get_completion(messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=300):\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature=temperature,\n","        max_tokens=max_tokens,\n","    )\n","    return response.choices[0].message[\"content\"]"]},{"cell_type":"markdown","metadata":{"id":"OHLJxr5B-hmd"},"source":["### Load the Data\n","\n","The code below loads both the few-shot demonstrations and the validation dataset used for testing the model."]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":446,"status":"ok","timestamp":1698764933942,"user":{"displayName":"Daniel Egbo","userId":"12843431213035929983"},"user_tz":-120},"id":"h1Q29ooc-hme"},"outputs":[],"source":["# print markdown\n","def print_markdown(text):\n","    \"\"\"Prints text as markdown\"\"\"\n","    IPython.display.display(IPython.display.Markdown(text))\n","\n","# load validation data from GitHub\n","f = urllib.request.urlopen(\"https://raw.githubusercontent.com/comet-ml/comet-llmops/main/data/article-tags.json\")\n","val_data = json.load(f)\n","\n","# load few shot data from GitHub\n","f = urllib.request.urlopen(\"https://raw.githubusercontent.com/comet-ml/comet-llmops/main/data/few_shot.json\")\n","few_shot_data = json.load(f)"]},{"cell_type":"markdown","metadata":{"id":"kkjHAZW0-hme"},"source":["The following is a helper function to obtain the final predictions from the model given a prompt template (e.g., zero-shot or few-shot) and the provided input data."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":435,"status":"ok","timestamp":1698764965417,"user":{"displayName":"Daniel Egbo","userId":"12843431213035929983"},"user_tz":-120},"id":"FOPd0RiP-hme"},"outputs":[],"source":["def get_predictions(prompt_template, inputs):\n","\n","    responses = []\n","\n","    for i in range(len(inputs)):\n","        messages = messages = [\n","            {\n","                \"role\": \"system\",\n","                \"content\": prompt_template.format(input=inputs[i])\n","            }\n","        ]\n","        response = get_completion(messages)\n","        responses.append(response)\n","\n","    return responses"]},{"cell_type":"markdown","metadata":{"id":"1Sbh8Rl1-hme"},"source":["### Few-Shot\n","\n","First, we define a few-shot template which will leverage the few-shot demonstration data loaded previously."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":409,"status":"ok","timestamp":1698765105330,"user":{"displayName":"Daniel Egbo","userId":"12843431213035929983"},"user_tz":-120},"id":"Ur-R41tr-hme"},"outputs":[],"source":["# function to define the few-shot template\n","def get_few_shot_template(few_shot_prefix, few_shot_suffix, few_shot_examples):\n","    return few_shot_prefix + \"\\n\\n\" + \"\\n\".join([ \"Abstract: \"+ ex[\"abstract\"] + \"\\n\" + \"Tags: \" + str(ex[\"tags\"]) + \"\\n\" for ex in few_shot_examples]) + \"\\n\\n\" + few_shot_suffix\n","\n","# function to sample few shot data\n","def random_sample_data (data, n):\n","    return np.random.choice(few_shot_data, n, replace=False)\n","\n","\n","# the few-shot prefix and suffix\n","few_shot_prefix = \"\"\"Your task is to extract model names from machine learning paper abstracts. Your response is an an array of the model names in the format [\\\"model_name\\\"]. If you don't find model names in the abstract or you are not sure, return [\\\"NA\\\"]\"\"\"\n","few_shot_suffix = \"\"\"Abstract: {input}\\nTags:\"\"\"\n","\n","# load 3 samples from few shot data\n","few_shot_template = get_few_shot_template(few_shot_prefix, few_shot_suffix, random_sample_data(few_shot_data, 3))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":446},"executionInfo":{"elapsed":415,"status":"ok","timestamp":1698765112240,"user":{"displayName":"Daniel Egbo","userId":"12843431213035929983"},"user_tz":-120},"id":"z716KoK2-hmf","outputId":"1c0f8c1a-9407-470b-8cdf-bf4b62487ee9"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Your task is to extract model names from machine learning paper abstracts. Your response is an an array of the model names in the format [\"model_name\"]. If you don\\'t find model names in the abstract or you are not sure, return [\"NA\"]\\n\\nAbstract: Prevalent semantic segmentation solutions are, in essence, a dense discriminative classifier of p(class|pixel feature). Though straightforward, this de facto paradigm neglects the underlying data distribution p(pixel feature|class), and struggles to identify out-of-distribution data. Going beyond this, we propose GMMSeg, a new family of segmentation models that rely on a dense generative classifier for the joint distribution p(pixel feature,class). For each class, GMMSeg builds Gaussian Mixture Models (GMMs) via Expectation-Maximization (EM), so as to capture class-conditional densities. Meanwhile, the deep dense representation is end-to-end trained in a discriminative manner, i.e., maximizing p(class|pixel feature). This endows GMMSeg with the strengths of both generative and discriminative models. With a variety of segmentation architectures and backbones, GMMSeg outperforms the discriminative counterparts on three closed-set datasets. More impressively, without any modification, GMMSeg even performs well on open-world datasets. We believe this work brings fundamental insights into the related fields.\\nTags: [\\'GMMSeg\\', \\'GMMs\\']\\n\\nAbstract: Neural Radiance Fields (NeRFs) are a very recent and very popular approach for the problems of novel view synthesis and 3D reconstruction. A popular scene representation used by NeRFs is to combine a uniform, voxel-based subdivision of the scene with an MLP. Based on the observation that a (sparse) point cloud of the scene is often available, this paper proposes to use an adaptive representation based on tetrahedra and a Delaunay representation instead of the uniform subdivision or point-based representations. We show that such a representation enables efficient training and leads to state-of-the-art results. Our approach elegantly combines concepts from 3D geometry processing, triangle-based rendering, and modern neural radiance fields. Compared to voxel-based representations, ours provides more detail around parts of the scene likely to be close to the surface. Compared to point-based representations, our approach achieves better performance.\\nTags: [\\'NeRFs\\', \\'MLP\\']\\n\\nAbstract: Topological deep learning is a rapidly growing field that pertains to the development of deep learning models for data supported on topological domains such as simplicial complexes, cell complexes, and hypergraphs, which generalize many domains encountered in scientific computations. In this paper, we present a unifying deep learning framework built upon a richer data structure that includes widely adopted topological domains. Specifically, we first introduce combinatorial complexes, a novel type of topological domain. Combinatorial complexes can be seen as generalizations of graphs that maintain certain desirable properties. Similar to hypergraphs, combinatorial complexes impose no constraints on the set of relations. In addition, combinatorial complexes permit the construction of hierarchical higher-order relations, analogous to those found in simplicial and cell complexes. Thus, combinatorial complexes generalize and combine useful traits of both hypergraphs and cell complexes, which have emerged as two promising abstractions that facilitate the generalization of graph neural networks to topological spaces. Second, building upon combinatorial complexes and their rich combinatorial and algebraic structure, we develop a general class of message-passing combinatorial complex neural networks (CCNNs), focusing primarily on attention-based CCNNs. We characterize permutation and orientation equivariances of CCNNs, and discuss pooling and unpooling operations within CCNNs in detail. Third, we evaluate the performance of CCNNs on tasks related to mesh shape analysis and graph learning. Our experiments demonstrate that CCNNs have competitive performance as compared to state-of-the-art deep learning models specifically tailored to the same tasks. Our findings demonstrate the advantages of incorporating higher-order relations into deep learning models in different applications.\\nTags: [\\'CCNNs\\']\\n\\n\\nAbstract: {input}\\nTags:'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["few_shot_template"]},{"cell_type":"markdown","metadata":{"id":"Jvvfx8ae-hmf"},"source":["### Zero-Shot Template\n","\n","The code below defines the zero-shot template. Note that we use the same instruction from the few-shot prompt template. But in this case, we don't use the demonstrations."]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":427,"status":"ok","timestamp":1698765215009,"user":{"displayName":"Daniel Egbo","userId":"12843431213035929983"},"user_tz":-120},"id":"wYvzzwYA-hmf"},"outputs":[],"source":["zero_shot_template = \"\"\"\n","Your task is extract model names from machine learning paper abstracts. Your response is an an array of the model names in the format [\\\"model_name\\\"]. If you don't find model names in the abstract or you are not sure, return [\\\"NA\\\"]\n","\n","Abstract: {input}\n","Tags:\n","\"\"\""]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1698765556965,"user":{"displayName":"Daniel Egbo","userId":"12843431213035929983"},"user_tz":-120},"id":"TxoP8HW-UM4z","outputId":"ae983c59-df0b-4ee1-e1a3-c900daf4d08e"},"outputs":[{"data":{"text/plain":["{'abstract': 'Training large language models (LLM) with open-domain instruction following data brings colossal success. However, manually creating such instruction data is very time-consuming and labor-intensive. Moreover, humans may struggle to produce high-complexity instructions. In this paper, we show an avenue for creating large amounts of instruction data with varying levels of complexity using LLM instead of humans. Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM. Human evaluations on a complexity-balanced test bed show that instructions from Evol-Instruct are superior to human-created ones. By analyzing the human evaluation results of the high complexity part, we demonstrate that outputs from our WizardLM model are preferred to outputs from OpenAI ChatGPT. Even though WizardLM still lags behind ChatGPT in some aspects, our findings suggest that fine-tuning with AI-evolved instructions is a promising direction for enhancing large language models. Our codes and generated data are public at',\n"," 'tags': ['LLaMA', 'ChatGPT', 'WizardLM']}"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["val_data[0]"]},{"cell_type":"markdown","metadata":{"id":"qwvsFEof-hmf"},"source":["### Get Predictions\n","\n","We then generated all the predictions using the validation data as inputs:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XGhppRv--hmg"},"outputs":[],"source":["# get the predictions\n","\n","abstracts = [val_data[i][\"abstract\"] for i in range(len(val_data[:3]))]\n","few_shot_predictions = get_predictions(few_shot_template, abstracts)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":17493,"status":"ok","timestamp":1698765746247,"user":{"displayName":"Daniel Egbo","userId":"12843431213035929983"},"user_tz":-120},"id":"e6K23DyyUsUP"},"outputs":[],"source":["zero_shot_predictions = get_predictions(zero_shot_template, abstracts)\n","expected_tags = [str(val_data[i][\"tags\"]) for i in range(len(val_data[:3]))]"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":696,"status":"ok","timestamp":1698765752124,"user":{"displayName":"Daniel Egbo","userId":"12843431213035929983"},"user_tz":-120},"id":"5to6iSU2-hmg","outputId":"82b56da2-b0f6-4a47-d7f4-5acae06f7880"},"outputs":[{"name":"stdout","output_type":"stream","text":["Few shot predictions\n","[\"['Evol-Instruct', 'LLaMA', 'WizardLM', 'ChatGPT']\", \"['FLAN-T5', 'AMR', 'UD', 'SRL', 'AMR2.0', 'AMR3.0', 'BioAMR', 'LoRA']\", '[\"NA\"]']\n","\n","\n","Zero shot predictions\n","['[\"WizardLM\", \"Evol-Instruct\", \"LLaMA\", \"ChatGPT\"]', '[\"FLAN-T5\"]', '[\"large language models\", \"generative AI\", \"hypothesis machines\"]']\n","\n","\n","Expected tags\n","[\"['LLaMA', 'ChatGPT', 'WizardLM']\", \"['FLAN-T5', 'FLAN']\", \"['NA']\"]\n"]}],"source":["print(\"Few shot predictions\")\n","print(few_shot_predictions)\n","print(\"\\n\\nZero shot predictions\")\n","print(zero_shot_predictions)\n","print(\"\\n\\nExpected tags\")\n","print(expected_tags)"]},{"cell_type":"markdown","metadata":{"id":"vq47EV18-hmg"},"source":["### Log Prompt Results\n","\n","Finally, we log the prompt + results to Comet. Note that we are logging both the few-shot and zero-shot results, together with all the metadata and tags."]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7567,"status":"ok","timestamp":1698765917154,"user":{"displayName":"Daniel Egbo","userId":"12843431213035929983"},"user_tz":-120},"id":"iBhWMBZa-hmg","outputId":"d6164b28-ae2e-4e02-aa0b-03b8a4ca04ed"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n"]},{"name":"stdout","output_type":"stream","text":["Prompt logged to https://www.comet.com/danselem/ml-paper-tagger-prompts\n"]},{"name":"stderr","output_type":"stream","text":["INFO:comet_llm.summary:Prompt logged to https://www.comet.com/danselem/ml-paper-tagger-prompts\n"]}],"source":["# log the predictions in Comet along with the ground truth for comparison\n","\n","# initialize comet\n","comet_llm.init(COMET_API_KEY, COMET_WORKSPACE, project=\"ml-paper-tagger-prompts\")\n","\n","# log the predictions\n","for i in range(len(expected_tags)):\n","    # log the few-shot predictions\n","    comet_llm.log_prompt(\n","        prompt=few_shot_template.format(input=abstracts[i]),\n","        prompt_template=few_shot_template,\n","        output=few_shot_predictions[i],\n","        tags = [\"gpt-3.5-turbo\", \"few-shot\"],\n","        metadata = {\n","            \"expected_tags\": expected_tags[i],\n","            \"abstract\": abstracts[i],\n","        }\n","    )\n","\n","    # log the zero-shot predictions\n","    comet_llm.log_prompt(\n","        prompt=zero_shot_template.format(input=abstracts[i]),\n","        prompt_template=zero_shot_template,\n","        output=zero_shot_predictions[i],\n","        tags = [\"gpt-3.5-turbo\", \"zero-shot\"],\n","        metadata = {\n","            \"expected_tags\": expected_tags[i],\n","            \"abstract\": abstracts[i],\n","        }\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hw2FK2YYVqvD"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"https://gist.github.com/caleb-kaiser/4e37a01c21c558a55825c3175e4744fd#file-2-prompt-tracking-comet-ipynb","timestamp":1698762712544}]},"kernelspec":{"display_name":"comet","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.17"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
